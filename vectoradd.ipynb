{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFeFnFQoCO9Z",
        "outputId": "8e79c834-604b-4cee-d51f-edc1965d0817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting addb.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile addb.cu\n",
        "#include<stdio.h>\n",
        "__global__ void add( int* a, int* b, int* c ) {\n",
        "c[blockIdx.x] = a[blockIdx.x] + b[blockIdx.x];\n",
        "}\n",
        "#define N 512\n",
        "int main( void ) {\n",
        "int *a, *b, *c; // host copies of a, b, c\n",
        "int *dev_a, *dev_b, *dev_c; // device copies of a, b, c\n",
        "int size = N *sizeof( int); // we need space for 512 integers\n",
        "// allocate device copies of a, b, c\n",
        "cudaMalloc( (void**)&dev_a, size );\n",
        "cudaMalloc( (void**)&dev_b, size );\n",
        "cudaMalloc( (void**)&dev_c, size );\n",
        "a = (int*)malloc( size );\n",
        "b = (int*)malloc( size );\n",
        "c = (int*)malloc( size );\n",
        "*a = 2;\n",
        "*b = 7;\n",
        "// copy inputs to device\n",
        "cudaMemcpy( dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy( dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "// launch add() kernel with N parallel blocks\n",
        "add<<< N, 1 >>>( dev_a, dev_b, dev_c);\n",
        "// copy device result back to host copy of c\n",
        "cudaMemcpy( c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "printf(\"Sum=%d\\n\", *c);\n",
        "free( a ); free( b ); free( c );\n",
        "cudaFree( dev_a);\n",
        "cudaFree( dev_b);\n",
        "cudaFree( dev_c);\n",
        "return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc addb.cu -o addb"
      ],
      "metadata": {
        "id": "oXwmAB_NDExM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./addb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIyiV44ZDtvz",
        "outputId": "bc345526-3daf-4a91-829e-6721a0d17e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum=9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vecmul.cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "__global__ void VecMul(float* A, float* B, float* C, int N)\n",
        "{\n",
        "\tint i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "\tif(i < N)\n",
        "\t\tC[i] = A[i]*B[i];\n",
        "}\n",
        "int main()\n",
        "{\n",
        "\tint i, N = 10;\n",
        "\tsize_t size = N * sizeof(float);\n",
        "\n",
        "\t// Allocating host and initializing\n",
        "\tfloat A[N],B[N],C[N];\n",
        "\tfor(i=0;i<N;i++) {\n",
        "\t\tA[i] = B[i] = i;\n",
        "\t}\n",
        "\n",
        "\t// Allocating device and copying to device\n",
        "\tfloat *d_A, *d_B, *d_C;\n",
        "\tcudaMalloc((void **)&d_A, size);\n",
        "\tcudaMalloc((void **)&d_B, size);\n",
        "\tcudaMalloc((void **)&d_C, size);\n",
        "\n",
        "\tcudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\t// Invoking kernel\n",
        "\tint threadsPerBlock = 8;\n",
        "\tint blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "\tVecMul<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "\t// Copy result from device to host\n",
        "\tcudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tfor(i=0;i<N;i++)\n",
        "\t\tprintf(\"%f\\n\", C[i]);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBvxP7PMDx2p",
        "outputId": "f846b3fd-6f84-4f12-e514-1cd16ad6bf32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vecmul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vecmul.cu -o vecmul"
      ],
      "metadata": {
        "id": "K40e06O7EFJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vecmul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STT4V6eCEPOa",
        "outputId": "49a2c2db-c35c-488a-9e13-9220f67d84df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.000000\n",
            "1.000000\n",
            "4.000000\n",
            "9.000000\n",
            "16.000000\n",
            "25.000000\n",
            "36.000000\n",
            "49.000000\n",
            "64.000000\n",
            "81.000000\n"
          ]
        }
      ]
    }
  ]
}